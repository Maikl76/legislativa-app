import requests
import json
import os
import pandas as pd
from flask import Flask, render_template, request, jsonify, redirect, url_for
from bs4 import BeautifulSoup
import fitz  # PyMuPDF
from dotenv import load_dotenv
import difflib  # Pro porovn√°n√≠ zmƒõn v dokumentech

# Naƒçten√≠ environment√°ln√≠ch promƒõnn√Ωch
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

app = Flask(__name__)
app.secret_key = "supersecretkey"

# Cesty pro soubory
SOURCES_FILE = "sources.txt"
HISTORY_DIR = "historie_pdfs"

if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)

# Inicializace datab√°ze
columns = ["N√°zev dokumentu", "Kategorie", "Datum vyd√°n√≠ / aktualizace", "Odkaz na zdroj", "Shrnut√≠ obsahu", "Soubor", "Kl√≠ƒçov√° slova", "P≈Øvodn√≠ obsah"]
legislativa_db = pd.DataFrame(columns=columns)
document_status = {}

# ‚úÖ Naƒçteme seznam webov√Ωch zdroj≈Ø
def load_sources():
    if os.path.exists(SOURCES_FILE):
        with open(SOURCES_FILE, "r", encoding="utf-8") as file:
            return [line.strip() for line in file.readlines()]
    return []

# ‚úÖ Ulo≈æ√≠me p≈Øvodn√≠ verzi dokumentu
def save_original_content(doc_name, content):
    file_path = os.path.join(HISTORY_DIR, f"{doc_name}.txt")
    with open(file_path, "w", encoding="utf-8") as file:
        file.write(content)

# ‚úÖ Naƒçteme p≈Øvodn√≠ verzi dokumentu, pokud existuje
def load_original_content(doc_name):
    file_path = os.path.join(HISTORY_DIR, f"{doc_name}.txt")
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()
    return ""

# ‚úÖ Porovn√°me star√Ω a nov√Ω text dokumentu
def compare_versions(old_text, new_text):
    if not old_text:
        return "Nov√Ω ‚úÖ"
    if old_text == new_text:
        return "Beze zmƒõny ‚ö™"
    return "Aktualizov√°no üü°"

# ‚úÖ St√°hneme PDF dokument a extrahujeme text
def extract_text_from_pdf(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            pdf_document = fitz.open(stream=response.content, filetype="pdf")
            return "\n".join([page.get_text("text") for page in pdf_document]).strip()
    except Exception as e:
        print("Chyba p≈ôi zpracov√°n√≠ PDF:", e)
    return ""

# ‚úÖ St√°hneme seznam pr√°vn√≠ch p≈ôedpis≈Ø z webu a kontrolujeme zmƒõny
def scrape_legislation(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        data = []
        for link in soup.find_all("a", href=True):
            href = link["href"]
            if href.endswith(".pdf"):
                name = link.text.strip()
                full_url = href if href.startswith("http") else url[:url.rfind("/")+1] + href
                new_text = extract_text_from_pdf(full_url)

                # ‚úÖ Naƒçteme star√Ω obsah a zjist√≠me zmƒõny
                old_text = load_original_content(name)
                status = compare_versions(old_text, new_text)

                # ‚úÖ Ulo≈æ√≠me nov√Ω obsah do historie
                save_original_content(name, new_text)

                document_status[name] = status
                data.append([name, "Legislativa", "N/A", url, "", full_url, "p≈ôedpisy", new_text])
        return pd.DataFrame(data, columns=columns)
    return pd.DataFrame(columns=columns)

# ‚úÖ Naƒçteme legislativn√≠ dokumenty
def load_initial_data():
    global legislativa_db
    urls = load_sources()
    legislativa_db = pd.concat([scrape_legislation(url) for url in urls], ignore_index=True)

load_initial_data()

# ‚úÖ API pro p≈ôid√°n√≠ nov√©ho webu
@app.route('/add_source', methods=['POST'])
def add_source():
    new_url = request.form.get("url").strip()
    if new_url:
        with open(SOURCES_FILE, "a", encoding="utf-8") as file:
            file.write(new_url + "\n")
        new_data = scrape_legislation(new_url)
        global legislativa_db
        legislativa_db = pd.concat([legislativa_db, new_data], ignore_index=True)
    return redirect(url_for('index'))

# ‚úÖ AI odpov√≠d√° na z√°kladƒõ v≈°ech dostupn√Ωch dokument≈Ø
def ask_openrouter(question):
    API_URL = "https://openrouter.ai/api/v1/chat/completions"

    extracted_texts = " ".join(legislativa_db["P≈Øvodn√≠ obsah"].tolist())  
    context = extracted_texts[:10000]  # ‚úÖ Omezen√≠ na 10 000 znak≈Ø

    HEADERS = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }

    DATA = {
        "model": "deepseek/deepseek-r1:free",
        "messages": [
            {"role": "system", "content": "Jsi AI expert na legislativu. Odpov√≠dej pouze na z√°kladƒõ n√≠≈æe uveden√Ωch dokument≈Ø."},
            {"role": "user", "content": f"Dokumenty:\n{context}\n\nOt√°zka: {question}"}
        ],
        "max_tokens": 750
    }

    try:
        response = requests.post(API_URL, headers=HEADERS, json=DATA, timeout=20)
        response.raise_for_status()
        response_json = response.json()
        return response_json["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        return f"Omlouv√°m se, do≈°lo k chybƒõ: {e}"

# ‚úÖ API pro AI asistenta
@app.route('/ask', methods=['POST'])
def ask():
    question = request.form.get("question", "").strip()
    if not question:
        return jsonify({"error": "Zadejte ot√°zku!"})
    return jsonify({"answer": ask_openrouter(question)})

# ‚úÖ Vyhled√°v√°n√≠ ve v≈°ech dokumentech
@app.route('/search', methods=['POST'])
def search():
    query = request.form.get("query", "").strip().lower()
    results = []

    if not query:
        return jsonify({"error": "Zadejte hledan√Ω v√Ωraz!"})

    for _, doc in legislativa_db.iterrows():
        for paragraph in doc["P≈Øvodn√≠ obsah"].split("\n\n"):
            if query in paragraph.lower():
                results.append({
                    "text": paragraph.strip(),
                    "document": doc["N√°zev dokumentu"],
                    "source": doc["Odkaz na zdroj"]
                })
                if len(results) >= 20:
                    break

    return jsonify(results)

# ‚úÖ Hlavn√≠ webov√° str√°nka
@app.route('/')
def index():
    return render_template('index.html', documents=legislativa_db.to_dict(orient="records"), sources=load_sources(), document_status=document_status)

if __name__ == '__main__':
    app.run(debug=True)
