from flask import Flask, render_template, request, jsonify
import os
import pandas as pd
import requests
from bs4 import BeautifulSoup
import fitz  # PyMuPDF
from dotenv import load_dotenv

# NaÄtenÃ­ environmentÃ¡lnÃ­ch promÄ›nnÃ½ch
load_dotenv()
# OvÄ›Å™enÃ­, zda se klÃ­Ä naÄetl sprÃ¡vnÄ›
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

if not OPENROUTER_API_KEY:
    print("âŒ CHYBA: API klÃ­Ä nebyl naÄten! Zkontroluj Render Environment Variables.")

else:
    print(f"âœ… API klÃ­Ä naÄten sprÃ¡vnÄ›: {OPENROUTER_API_KEY[:5]}... (skrytÃ½ pro bezpeÄnost)")

app = Flask(__name__)
app.secret_key = "supersecretkey"

# NaÄtenÃ­ API klÃ­Äe pro OpenRouter
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

# Cesty pro uklÃ¡dÃ¡nÃ­ dat
SOURCES_FILE = "sources.txt"
HISTORY_DIR = "historie_pdfs"

if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)

# Inicializace databÃ¡ze
columns = ["NÃ¡zev dokumentu", "Kategorie", "Datum vydÃ¡nÃ­ / aktualizace", "Odkaz na zdroj", "ShrnutÃ­ obsahu", "Soubor", "KlÃ­ÄovÃ¡ slova", "PÅ¯vodnÃ­ obsah"]
legislativa_db = pd.DataFrame(columns=columns)
document_status = {}

def load_sources():
    """ NaÄte seznam sledovanÃ½ch URL ze souboru sources.txt. """
    if os.path.exists(SOURCES_FILE):
        with open(SOURCES_FILE, "r", encoding="utf-8") as file:
            return [line.strip() for line in file.readlines()]
    return []

def extract_text_from_pdf(url):
    """ StÃ¡hne PDF a extrahuje text. """
    try:
        response = requests.get(url)
        if response.status_code == 200:
            pdf_document = fitz.open(stream=response.content, filetype="pdf")
            return "\n".join([page.get_text("text") for page in pdf_document]).strip()
    except Exception as e:
        print("Chyba pÅ™i zpracovÃ¡nÃ­ PDF:", e)
    return ""

def scrape_legislation(url):
    """ StÃ¡hne seznam PDF dokumentÅ¯ a jejich obsah. """
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        data = []
        for link in soup.find_all("a", href=True):
            href = link["href"]
            if href.endswith(".pdf"):
                name = link.text.strip()
                full_url = href if href.startswith("http") else url[:url.rfind("/")+1] + href
                text_content = extract_text_from_pdf(full_url)
                data.append([name, "Legislativa", "N/A", url, "", full_url, "pÅ™edpisy", text_content])
        return pd.DataFrame(data, columns=columns)
    return pd.DataFrame(columns=columns)

def load_initial_data():
    """ NaÄte data pÅ™i startu aplikace """
    global legislativa_db
    urls = load_sources()
    legislativa_db = pd.concat([scrape_legislation(url) for url in urls], ignore_index=True)

load_initial_data()  # ğŸ†• NaÄteme dokumenty pÅ™i startu aplikace

def ask_openrouter(question, context):
    """ OdesÃ­lÃ¡ dotaz na OpenRouter API (s debug logem) """
    API_URL = "https://openrouter.ai/api/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENROUTER_API_KEY}"}

    data = {
        "model": "mistralai/mistral-small-24b-instruct-2501:free",
        "messages": [
            {"role": "system", "content": "Jsi AI expert na legislativu. OdpovÃ­dej jasnÄ› a pÅ™esnÄ›."},
            {"role": "user", "content": f"Zde je kontext: {context}\n\nOtÃ¡zka: {question}"}
        ],
        "max_tokens": 500
    }

    print(f"ğŸŸ¡ ODESÃLÃM API REQUEST: {data}")  # ğŸ›  Debug log

    response = requests.post(API_URL, headers=headers, json=data)

    if response.status_code == 200:
        print(f"ğŸŸ¢ API RESPONSE: {response.json()}")  # ğŸ›  Debug log
        return response.json()["choices"][0]["message"]["content"]
    else:
        print(f"ğŸ”´ CHYBA PÅ˜I API POÅ½ADAVKU ({response.status_code}): {response.text}")  # ğŸ›  Debug log
        return f"OmlouvÃ¡m se, doÅ¡lo k chybÄ›: {response.status_code}"

@app.route('/')
def index():
    sources = load_sources()
    return render_template('index.html', documents=legislativa_db.to_dict(orient="records"), sources=sources, document_status=document_status)

@app.route('/search', methods=['POST'])
def search():
    query = request.form.get("query", "").strip().lower()
    results = []

    if not query:
        return jsonify({"error": "Zadejte hledanÃ½ vÃ½raz!"})

    for _, doc in legislativa_db.iterrows():
        text = doc["PÅ¯vodnÃ­ obsah"]
        paragraphs = text.split("\n\n")
        for paragraph in paragraphs:
            if query in paragraph.lower():
                results.append({"text": paragraph.strip(), "document": doc["NÃ¡zev dokumentu"], "source": doc["Odkaz na zdroj"]})

    return jsonify(results)

@app.route('/ask', methods=['POST'])
def ask():
    question = request.form.get("question", "").strip()
    if not question:
        return jsonify({"error": "Zadejte otÃ¡zku!"})
    
    context = " ".join(legislativa_db["PÅ¯vodnÃ­ obsah"].tolist()[:3])  # ğŸ†• PouÅ¾ijeme prvnÃ­ 3 dokumenty jako kontext
    answer = ask_openrouter(question, context)
    
    return jsonify({"answer": answer})

if __name__ == '__main__':
    app.run(debug=True)
