import os
import requests
import json
import pandas as pd
import logging
import psutil
from flask import Flask, render_template, request, jsonify, redirect, url_for
from bs4 import BeautifulSoup
import fitz  # PyMuPDF
from dotenv import load_dotenv
import difflib
from groq import Groq

# ‚úÖ Naƒçten√≠ environment√°ln√≠ch promƒõnn√Ωch
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# ‚úÖ Inicializace Groq klienta
client = Groq(api_key=GROQ_API_KEY)

# ‚úÖ Konfigurace Flask aplikace
app = Flask(__name__)
app.secret_key = "supersecretkey"

# ‚úÖ Logov√°n√≠ do souboru
logging.basicConfig(level=logging.DEBUG, filename='app.log', filemode='a', format='%(asctime)s - %(levelname)s - %(message)s')

# ‚úÖ Cesty pro soubory
SOURCES_FILE = "sources.txt"
HISTORY_DIR = "historie_pdfs"

if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)

# ‚úÖ Datab√°ze dokument≈Ø
columns = ["N√°zev dokumentu", "Kategorie", "Datum vyd√°n√≠", "Odkaz na zdroj", "Soubor", "Kl√≠ƒçov√° slova", "P≈Øvodn√≠ obsah", "Status"]
legislativa_db = pd.DataFrame(columns=columns)
document_status = {}

# ‚úÖ Naƒçten√≠ webov√Ωch zdroj≈Ø
def load_sources():
    if os.path.exists(SOURCES_FILE):
        with open(SOURCES_FILE, "r", encoding="utf-8") as file:
            return [line.strip() for line in file.readlines()]
    return []

# ‚úÖ Ulo≈æen√≠ webov√Ωch zdroj≈Ø
def save_sources(sources):
    with open(SOURCES_FILE, "w", encoding="utf-8") as file:
        for source in sources:
            file.write(source + "\n")

# ‚úÖ Extrahov√°n√≠ textu z PDF
def extract_text_from_pdf(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            pdf_document = fitz.open(stream=response.content, filetype="pdf")
            return "\n".join([page.get_text("text") for page in pdf_document]).strip()
    except Exception as e:
        logging.error(f"‚ùå Chyba p≈ôi zpracov√°n√≠ PDF: {e}")
    return ""

# ‚úÖ Sta≈æen√≠ dokument≈Ø a kontrola zmƒõn
def scrape_legislation(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        data = []
        for link in soup.find_all("a", href=True):
            href = link["href"]
            if href.endswith(".pdf"):
                name = link.text.strip()
                full_url = href if href.startswith("http") else url[:url.rfind("/")+1] + href
                new_content = extract_text_from_pdf(full_url)

                # Kontrola zmƒõn dokument≈Ø
                status = "Nov√Ω ‚úÖ"
                if name in document_status:
                    old_content = document_status[name]
                    if old_content != new_content:
                        status = "Aktualizov√°n üü°"
                    else:
                        status = "Beze zmƒõny ‚ö™"
                document_status[name] = new_content

                data.append([name, "Legislativa", "N/A", url, full_url, "p≈ôedpisy", new_content, status])

        return pd.DataFrame(data, columns=columns)
    return pd.DataFrame(columns=columns)

# ‚úÖ Naƒçten√≠ dokument≈Ø
def load_initial_data():
    global legislativa_db
    urls = load_sources()
    legislativa_db = pd.concat([scrape_legislation(url) for url in urls], ignore_index=True)

load_initial_data()

# ‚úÖ P≈ôid√°n√≠ nov√©ho zdroje
@app.route('/add_source', methods=['POST'])
def add_source():
    new_url = request.form.get("url").strip()
    if new_url:
        sources = load_sources()
        if new_url not in sources:
            sources.append(new_url)
            save_sources(sources)
            new_data = scrape_legislation(new_url)
            global legislativa_db
            legislativa_db = pd.concat([legislativa_db, new_data], ignore_index=True)
    return redirect(url_for('index'))

# ‚úÖ Odstranƒõn√≠ zdroje
@app.route('/remove_source', methods=['POST'])
def remove_source():
    url_to_remove = request.form.get("url").strip()
    sources = load_sources()
    if url_to_remove in sources:
        sources.remove(url_to_remove)
        save_sources(sources)
        global legislativa_db
        legislativa_db = legislativa_db[legislativa_db["Odkaz na zdroj"] != url_to_remove]
    return redirect(url_for('index'))

# ‚úÖ AI odpov√≠d√° na z√°kladƒõ dokument≈Ø pomoc√≠ Groq API
def ask_groq(question, source):
    logging.debug(f"üîç Dotaz na AI: {question}")
    logging.debug(f"üìÇ Zdroj: {source}")

    selected_docs = legislativa_db[legislativa_db["Odkaz na zdroj"] == source]

    if selected_docs.empty:
        logging.warning("‚ö†Ô∏è Nebyly nalezeny ≈æ√°dn√© dokumenty pro tento zdroj.")
        return "‚ö†Ô∏è Nebyly nalezeny ≈æ√°dn√© dokumenty pro tento zdroj."

    extracted_texts = " ".join(selected_docs["P≈Øvodn√≠ obsah"].tolist())

    try:
        # ‚úÖ Odes√≠l√°me dotaz na Groq API
        completion = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=[
                {"role": "system", "content": "Jsi AI expert na legislativu."},
                {"role": "user", "content": f"Dokumenty:\n{extracted_texts[:3000]}\n\nOt√°zka: {question}"}
            ],
            temperature=1,
            max_tokens=512,
            top_p=1
        )

        logging.debug(f"üü¢ Odpovƒõƒè Groq API: {completion}")

        if not completion.choices:
            logging.error("‚ùå Groq API nevr√°tilo ≈æ√°dnou odpovƒõƒè!")
            return "‚ö†Ô∏è Groq API nevr√°tilo ≈æ√°dnou odpovƒõƒè."

        return completion.choices[0].message.content

    except Exception as e:
        logging.error(f"‚õî Chyba p≈ôi vol√°n√≠ Groq API: {e}")
        return f"‚ö†Ô∏è Chyba p≈ôi vol√°n√≠ Groq API: {e}"

# ‚úÖ API pro AI asistenta
@app.route('/ask', methods=['POST'])
def ask():
    question = request.form.get("question", "").strip()
    source = request.form.get("source", "").strip()
    if not question or not source:
        return jsonify({"error": "Zadejte ot√°zku a vyberte zdroj!"})
    return jsonify({"answer": ask_groq(question, source)})

# ‚úÖ Hlavn√≠ webov√° str√°nka
@app.route('/')
def index():
    return render_template('index.html', documents=legislativa_db.to_dict(orient="records"), sources=load_sources(), document_status=document_status)

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=5000, debug=True)
